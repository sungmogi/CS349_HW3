{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your architecture should consist of a single hidden layer with up to k nodes.\n",
    "- You can use any activation function (e.g., sigmoid, tanh, etc.) in the hidden nodes.\n",
    "- Your model must use a bias term at the input and hidden layers. It can be a standalone term or\n",
    "be incorporated in the weight matrices.\n",
    "- You should use gradient descent to train your FFNN.\n",
    "- You may find it helpful to use random number seeds for reproducibility when debugging.\n",
    "- You do not need to use a GPU for this assignment, and your models should train in less than one\n",
    "minute each.\n",
    "- You are responsible for selecting hyperparameters (e.g., number of hidden nodes, learning rate,\n",
    "training epochs, batch sizes, early stopping criteria, lambda, etc.). The goal is to get “good”\n",
    "performance from your model, but an exhaustive hyper-parameter search is unnecessary.\n",
    "- All code, exhibits and answers to free-response questions must be in a single Jupyter notebook.\n",
    "- Your code should use parameters to control all functionality needed to complete specific tasks\n",
    "(see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleLayerFFNN(nn.Module):\n",
    "    def __init__(self, hidden_size, activation_fn=\"sigmoid\"):\n",
    "        super(SingleLayerFFNN, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(2, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, 2, bias=True)\n",
    "\n",
    "        if activation_fn == \"sigmoid\":\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation_fn == \"tanh\":\n",
    "            self.activation = torch.tanh\n",
    "        elif activation_fn == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # One hidden layer\n",
    "        hidden = self.activation(self.input_layer(x))\n",
    "        output = self.output_layer(hidden)\n",
    "\n",
    "        return output\n",
    "    \n",
    "        # probabilities = F.softmax(output, dim=1)\n",
    "\n",
    "        # return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, num_epochs, learning_rate):\n",
    "    # nn.CrossEntropyLoss for multiclass cross entropy\n",
    "    # nn.MSELoss for mean squared error\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # loss for this epoch\n",
    "        epoch_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def load_data(file_path, batch_size):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader) # skip header row\n",
    "        for row in reader:\n",
    "            labels.append(float(row[0]))\n",
    "            inputs.append([float(row[1]), float(row[2])])\n",
    "\n",
    "    inputs_tensor = torch.tensor(inputs, dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(inputs_tensor, labels_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.7024\n",
      "Epoch 2/20, Loss: 0.6872\n",
      "Epoch 3/20, Loss: 0.6868\n",
      "Epoch 4/20, Loss: 0.6862\n",
      "Epoch 5/20, Loss: 0.6857\n",
      "Epoch 6/20, Loss: 0.6853\n",
      "Epoch 7/20, Loss: 0.6849\n",
      "Epoch 8/20, Loss: 0.6845\n",
      "Epoch 9/20, Loss: 0.6842\n",
      "Epoch 10/20, Loss: 0.6839\n",
      "Epoch 11/20, Loss: 0.6836\n",
      "Epoch 12/20, Loss: 0.6833\n",
      "Epoch 13/20, Loss: 0.6831\n",
      "Epoch 14/20, Loss: 0.6829\n",
      "Epoch 15/20, Loss: 0.6827\n",
      "Epoch 16/20, Loss: 0.6825\n",
      "Epoch 17/20, Loss: 0.6823\n",
      "Epoch 18/20, Loss: 0.6821\n",
      "Epoch 19/20, Loss: 0.6820\n",
      "Epoch 20/20, Loss: 0.6818\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train model with train set. \n",
    "Hyperparameters: hidden_size, batch_size, num_epochs, learning_rate\n",
    "'''\n",
    "\n",
    "file_path = \"xor_train.csv\"\n",
    "\n",
    "# hidden_size from [2, 3, 5, 7, 9] \n",
    "hidden_size = 9\n",
    "batch_size = 2\n",
    "# activation from \"sigmoid\", \"relu\", \"tanh\"\n",
    "activation_fn = \"sigmoid\"\n",
    "num_epochs = 20\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loader = load_data(file_path, batch_size)\n",
    "model = SingleLayerFFNN(hidden_size, activation_fn)\n",
    "\n",
    "train_model(model, train_loader, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_targets.extend(target.numpy())\n",
    "\n",
    "    all_preds = torch.tensor(all_preds)\n",
    "    all_targets = torch.tensor(all_targets)\n",
    "    \n",
    "    correct = (all_preds == all_targets).sum().item()\n",
    "    total = len(all_targets)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.455"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_file_path = \"xor_valid.csv\"\n",
    "eval_batch_size = 4\n",
    "\n",
    "eval_loader = load_data(eval_file_path, eval_batch_size)\n",
    "evaluate_model(model, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Grid Search\n",
    "'''\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [16, 32]\n",
    "num_epochs_list = [10, 20]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs349",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
